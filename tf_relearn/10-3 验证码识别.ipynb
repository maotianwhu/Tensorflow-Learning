{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xc but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xc but this version of numpy is 0xa"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xc but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xc but this version of numpy is 0xa"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "# 多任务学习，交替训练，联合训练\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from nets import nets_factory\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不同字符数量\n",
    "CHAR_SET_LEN = 10\n",
    "# 图片高度\n",
    "IMAGE_HEIGHT = 60\n",
    "# 图片高度\n",
    "IMAGE_WIDTH = 160\n",
    "# 批次\n",
    "BATCH_SIZE = 25\n",
    "# tfrecords文件存放路径\n",
    "TFRECORD_FILE = ['captcha/images_train_00000-of-00002.tfrecord', 'captcha/images_train_00001-of-00002.tfrecord']\n",
    "\n",
    "# placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 224, 224])\n",
    "y0 = tf.placeholder(tf.float32, [None])\n",
    "y1 = tf.placeholder(tf.float32, [None])\n",
    "y2 = tf.placeholder(tf.float32, [None])\n",
    "y3 = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "\n",
    "# 学习率\n",
    "lr = tf.Variable(0.003, dtype=tf.float32)\n",
    "\n",
    "# 从tfrecord读出数据\n",
    "def read_and_decode(filename):\n",
    "    # 根据文件名生成一个队列\n",
    "    filename_queue = tf.train.string_input_producer(filename)\n",
    "    reader = tf.TFRecordReader()\n",
    "    # 返回文件名和文件\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                      features={\n",
    "                                          'image': tf.FixedLenFeature([], tf.string),\n",
    "                                          'label0': tf.FixedLenFeature([], tf.int64),\n",
    "                                          'label1': tf.FixedLenFeature([], tf.int64),\n",
    "                                          'label2': tf.FixedLenFeature([], tf.int64),\n",
    "                                          'label3': tf.FixedLenFeature([], tf.int64),\n",
    "                                      })\n",
    "    \n",
    "    # 获取图片数据\n",
    "    image = tf.decode_raw(features['image'], tf.uint8)\n",
    "    \n",
    "    # tf.train.shuffle_batch 必须确定shape\n",
    "    image = tf.reshape(image, [224, 224])\n",
    "    # 图片预处理\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.subtract(image, 0.5)\n",
    "    image = tf.multiply(image, 2.0)\n",
    "    \n",
    "    # 获取label\n",
    "    label0 = tf.cast(features['label0'], tf.int32)\n",
    "    label1 = tf.cast(features['label1'], tf.int32)\n",
    "    label2 = tf.cast(features['label2'], tf.int32)\n",
    "    label3 = tf.cast(features['label3'], tf.int32)\n",
    "    \n",
    "    return image, label0, label1, label2, label3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取图片数据和标签\n",
    "image, label0, label1, label2, label3 = read_and_decode(TFRECORD_FILE)\n",
    "\n",
    "# 使用shuffle_batch可以随机打乱\n",
    "image_batch, label_batch0, label_batch1, label_batch2, label_batch3 = tf.train.shuffle_batch([image, label0, label1, label2, label3], batch_size = BATCH_SIZE, capacity = 50000, min_after_dequeue=10000, num_threads=2)\n",
    "# print image_batch.shape, label_batch0.shape\n",
    "\n",
    "train_network_fn = nets_factory.get_network_fn('alexnet_v2', num_classes=CHAR_SET_LEN, weight_decay=0.0005, is_training=True)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # inputs: a tensor of size [batch_size, height, width, channels]\n",
    "    X = tf.reshape(x, [BATCH_SIZE, 224, 224, 1])\n",
    "    logits0, logits1, logits2, logits3, end_points = train_network_fn(X)\n",
    "    \n",
    "    # 把标签转换成one_hot格式\n",
    "    one_hot_label0 = tf.one_hot(indices=tf.cast(y0, tf.int32), depth=CHAR_SET_LEN)\n",
    "    one_hot_label1 = tf.one_hot(indices=tf.cast(y1, tf.int32), depth=CHAR_SET_LEN)\n",
    "    one_hot_label2 = tf.one_hot(indices=tf.cast(y2, tf.int32), depth=CHAR_SET_LEN)\n",
    "    one_hot_label3 = tf.one_hot(indices=tf.cast(y3, tf.int32), depth=CHAR_SET_LEN)\n",
    "\n",
    "    # 计算loss\n",
    "    loss0 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits0, labels=one_hot_label0))\n",
    "    loss1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits1, labels=one_hot_label1))\n",
    "    loss2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits2, labels=one_hot_label2))\n",
    "    loss3 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits3, labels=one_hot_label3))\n",
    "    \n",
    "    # 计算总的loss\n",
    "    total_loss = (loss0 + loss1 + loss2 + loss3) / 4.0\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(total_loss)\n",
    "    \n",
    "    # 计算准确率\n",
    "    correct_prediction0 = tf.equal(tf.argmax(one_hot_label0, 1), tf.argmax(logits0, 1))\n",
    "    accuracy0 = tf.reduce_mean(tf.cast(correct_prediction0, tf.float32))\n",
    "    \n",
    "    correct_prediction1 = tf.equal(tf.argmax(one_hot_label1, 1), tf.argmax(logits1, 1))\n",
    "    accuracy1 = tf.reduce_mean(tf.cast(correct_prediction1, tf.float32))\n",
    "    \n",
    "    correct_prediction2 = tf.equal(tf.argmax(one_hot_label2, 1), tf.argmax(logits2, 1))\n",
    "    accuracy2 = tf.reduce_mean(tf.cast(correct_prediction2, tf.float32))\n",
    "    \n",
    "    correct_prediction3 = tf.equal(tf.argmax(one_hot_label3, 1), tf.argmax(logits3, 1))\n",
    "    accuracy3 = tf.reduce_mean(tf.cast(correct_prediction3, tf.float32))\n",
    "    \n",
    "    # 用于保存模型\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # 初始化\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # 创建一个协调器，管理线程\n",
    "    coord = tf.train.Coordinator()\n",
    "    # 启动QueueRunner，此时文件名队列已经进队\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    \n",
    "    for i in range(6001):\n",
    "        # 获取一个批次的数据和标签\n",
    "        b_image, b_label0, b_label1, b_label2, b_label3 = sess.run([image_batch, label_batch0, label_batch1, label_batch2, label_batch3])\n",
    "        # 优化模型\n",
    "        sess.run(optimizer, feed_dict={x: b_image, y0: b_label0, y1: b_label1, y2: b_label2, y3: b_label3})\n",
    "        \n",
    "        # 每迭代20次计算一次loss和准确率\n",
    "        if i % 200 == 0:\n",
    "            # 每迭代2000次降低一次学习率\n",
    "            if i % 2000 == 0:\n",
    "                sess.run(tf.assign(lr, lr/3))\n",
    "            acc0, acc1, acc2, acc3, loss_ = sess.run([accuracy0, accuracy1, accuracy2, accuracy3, total_loss], feed_dict={x: b_image, y0: b_label0, y1: b_label1, y2: b_label2, y3: b_label3})\n",
    "            \n",
    "            learning_rate = sess.run(lr)\n",
    "            \n",
    "            print \"Iter: %d  Loss: %.3f  Accuracy: %.2f, %.2f, %.2f, %.2f  Learning_rate: %.4f\" % (i, loss_, acc0, acc1, acc2, acc3, learning_rate)\n",
    "            \n",
    "            if i % 6000 == 0:\n",
    "                saver.save(sess, './captcha/model/crack_captcha.model', global_step=i)\n",
    "    \n",
    "    # 通知其他线程关闭\n",
    "    coord.request_stop()\n",
    "    # 其他所有线程关闭后，这一函数才能返回\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面是我在GPU服务器的训练结果\n",
    "# 代码整理于 https://github.com/zhulf0804/Verification-Code-Recognition\n",
    "\n",
    "Iter: 0  Loss: 2696.982  Accuracy: 0.16, 0.20, 0.28, 0.24  Learning_rate: 0.0010\n",
    "Iter: 200  Loss: 2.302  Accuracy: 0.20, 0.08, 0.04, 0.12  Learning_rate: 0.0010\n",
    "Iter: 400  Loss: 2.312  Accuracy: 0.16, 0.12, 0.04, 0.00  Learning_rate: 0.0010\n",
    "Iter: 600  Loss: 2.320  Accuracy: 0.08, 0.16, 0.04, 0.04  Learning_rate: 0.0010\n",
    "Iter: 800  Loss: 2.213  Accuracy: 0.28, 0.24, 0.08, 0.20  Learning_rate: 0.0010\n",
    "Iter: 1000  Loss: 1.817  Accuracy: 0.28, 0.20, 0.32, 0.52  Learning_rate: 0.0010\n",
    "Iter: 1200  Loss: 1.456  Accuracy: 0.48, 0.28, 0.56, 0.40  Learning_rate: 0.0010\n",
    "Iter: 1400  Loss: 1.037  Accuracy: 0.56, 0.52, 0.60, 0.76  Learning_rate: 0.0010\n",
    "Iter: 1600  Loss: 0.947  Accuracy: 0.84, 0.56, 0.36, 0.88  Learning_rate: 0.0010\n",
    "Iter: 1800  Loss: 0.507  Accuracy: 0.84, 0.76, 0.76, 0.88  Learning_rate: 0.0010\n",
    "Iter: 2000  Loss: 0.601  Accuracy: 0.80, 0.76, 0.68, 0.72  Learning_rate: 0.0003\n",
    "Iter: 2200  Loss: 0.469  Accuracy: 0.84, 0.88, 0.76, 0.92  Learning_rate: 0.0003\n",
    "Iter: 2400  Loss: 0.427  Accuracy: 0.92, 0.80, 0.80, 0.96  Learning_rate: 0.0003\n",
    "Iter: 2600  Loss: 0.425  Accuracy: 0.88, 0.76, 0.88, 0.96  Learning_rate: 0.0003\n",
    "Iter: 2800  Loss: 0.176  Accuracy: 0.96, 0.96, 1.00, 0.88  Learning_rate: 0.0003\n",
    "Iter: 3000  Loss: 0.202  Accuracy: 0.92, 0.96, 0.84, 0.96  Learning_rate: 0.0003\n",
    "Iter: 3200  Loss: 0.243  Accuracy: 0.96, 0.96, 0.92, 0.80  Learning_rate: 0.0003\n",
    "Iter: 3400  Loss: 0.172  Accuracy: 0.92, 0.96, 0.92, 0.96  Learning_rate: 0.0003\n",
    "Iter: 3600  Loss: 0.342  Accuracy: 0.92, 0.92, 0.92, 0.92  Learning_rate: 0.0003\n",
    "Iter: 3800  Loss: 0.150  Accuracy: 0.96, 0.96, 0.92, 0.96  Learning_rate: 0.0003\n",
    "Iter: 4000  Loss: 0.177  Accuracy: 0.92, 0.88, 0.96, 0.96  Learning_rate: 0.0001\n",
    "Iter: 4200  Loss: 0.125  Accuracy: 1.00, 0.92, 0.96, 0.92  Learning_rate: 0.0001\n",
    "Iter: 4400  Loss: 0.114  Accuracy: 1.00, 0.92, 1.00, 1.00  Learning_rate: 0.0001\n",
    "Iter: 4600  Loss: 0.128  Accuracy: 1.00, 1.00, 0.84, 1.00  Learning_rate: 0.0001\n",
    "Iter: 4800  Loss: 0.100  Accuracy: 1.00, 0.92, 0.96, 0.96  Learning_rate: 0.0001\n",
    "Iter: 5000  Loss: 0.075  Accuracy: 1.00, 0.96, 1.00, 0.96  Learning_rate: 0.0001\n",
    "Iter: 5200  Loss: 0.061  Accuracy: 0.96, 1.00, 0.96, 1.00  Learning_rate: 0.0001\n",
    "Iter: 5400  Loss: 0.098  Accuracy: 1.00, 0.96, 0.88, 1.00  Learning_rate: 0.0001\n",
    "Iter: 5600  Loss: 0.145  Accuracy: 1.00, 0.96, 0.88, 0.96  Learning_rate: 0.0001\n",
    "Iter: 5800  Loss: 0.090  Accuracy: 1.00, 1.00, 0.96, 0.96  Learning_rate: 0.0001\n",
    "Iter: 6000  Loss: 0.079  Accuracy: 1.00, 1.00, 0.92, 0.96  Learning_rate: 0.0000\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
